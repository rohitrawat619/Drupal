{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1RFyOcdXUmLlBLLqcyvxplRIlb0R9Z8FE","authorship_tag":"ABX9TyODUKZ1u83Tid/r+fCARipu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"A3lVS5B_YftW","executionInfo":{"status":"ok","timestamp":1760859509627,"user_tz":-60,"elapsed":11772,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}}},"outputs":[],"source":["# ---- Standard numeric + data libraries\n","import numpy as np                     # Numerical arrays and math helpers\n","import pandas as pd                    # DataFrames for tabular data\n","\n","# ---- Scikit-learn model building utilities\n","from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV  # Splits + CV search\n","from sklearn.preprocessing import StandardScaler                                      # Feature scaling (mean 0, std 1)\n","from sklearn.pipeline import Pipeline                                                 # Chain steps into one model\n","from sklearn.linear_model import LogisticRegression                                   # Our classifier\n","from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix    # Model evaluation metrics\n","from sklearn.cluster import KMeans                                                    # Unsupervised clustering to create \"phenotypes\"\n","\n","# ---- Statistics (for simple drift detection)\n","from scipy.stats import ks_2samp"]},{"cell_type":"code","source":["# -----------------------------\n","# 0) Configuration & utilities\n","# -----------------------------\n","\n","RANDOM_STATE = 42                 # Fixed seed for reproducibility\n","N_CLUSTERS = 4                    # Number of KMeans clusters (phenotype groups)\n","CV_SPLITS = 5                     # Number of folds for cross-validation\n","SCORING = \"f1\"                    # Optimize for F1 (balance of precision & recall)\n","EPS = 1e-6                        # Tiny constant to avoid divide-by-zero\n","DRIFT_PVAL_THRESHOLD = 0.01       # KS-test p-value threshold for declaring \"drift detected\"\n","\n","def evaluate(model, X, y, title=\"Evaluation\"):\n","    \"\"\"\n","    Evaluate a trained classifier with common metrics and print results.\n","    This function:\n","      - gets predictions and predicted probabilities,\n","      - prints a classification report (precision/recall/F1 by class),\n","      - prints ROC-AUC (threshold-free quality),\n","      - prints the confusion matrix (TN, FP / FN, TP).\n","    \"\"\"\n","    y_pred = model.predict(X)                                    # Discrete predictions (0 or 1)\n","    y_proba = model.predict_proba(X)[:, 1]                       # Probability of class 1 (if classifier supports it)\n","    print(f\"\\n=== {title} ===\")                                  # Section title\n","    print(classification_report(y, y_pred, digits=3))            # Precision/Recall/F1 per class\n","    print(\"ROC-AUC:\", round(roc_auc_score(y, y_proba), 3))       # Area under ROC curve (ranking quality)\n","    print(\"Confusion matrix:\\n\", confusion_matrix(y, y_pred))    # TN FP / FN TP layout\n","\n","def ks_drift(old_df, new_df, cols, p_thresh=DRIFT_PVAL_THRESHOLD):\n","    \"\"\"\n","    Lightweight drift check using the Kolmogorovâ€“Smirnov test per numeric column.\n","    Compares distributions of 'old_df[col]' vs 'new_df[col]'.\n","    Returns True if ANY column shows p-value < threshold (i.e., statistically different).\n","    \"\"\"\n","    for c in cols:                                               # Iterate over shared columns\n","        if c in old_df.columns and c in new_df.columns:          # Only test if both datasets have this column\n","            a = pd.to_numeric(old_df[c], errors=\"coerce\")        # Convert to numeric (coerce errors to NaN)\n","            b = pd.to_numeric(new_df[c], errors=\"coerce\")        # Convert to numeric for new data\n","            a = a.replace([np.inf, -np.inf], np.nan).dropna()    # Remove inf and NaN to clean arrays\n","            b = b.replace([np.inf, -np.inf], np.nan).dropna()    # Same cleaning for new data\n","            if len(a) > 30 and len(b) > 30:                      # Guard: need enough samples to test\n","                _, p = ks_2samp(a, b)                            # Perform KS test (returns statistic, p-value)\n","                if p < p_thresh:                                 # If p is small, distributions differ => drift\n","                    return True                                   # Early return on first detected drift\n","    return False"],"metadata":{"id":"2AkYwL56Z4rL","executionInfo":{"status":"ok","timestamp":1760859575593,"user_tz":-60,"elapsed":59,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# -------------------------------------\n","# 1) Load data  (adjust path if needed)\n","# -------------------------------------\n","\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/diabetes_1.csv')                            # Load dataset from CSV\n","\n","X_full = df.drop(columns=[\"Outcome\"]).copy()                    # All input features (drop the target column)\n","y_full = df[\"Outcome\"].astype(int).copy()                       # Target labels as integers (0 or 1)\n","\n","numeric_cols = X_full.columns.tolist()"],"metadata":{"id":"NMY1sZrLaNQO","executionInfo":{"status":"ok","timestamp":1760859788107,"user_tz":-60,"elapsed":307,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Missing values\n","print(df.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ywNY4JYaSOa","executionInfo":{"status":"ok","timestamp":1760859813847,"user_tz":-60,"elapsed":8,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"e167aa0b-a1fe-45a4-8218-b9629c2076e5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Pregnancies                 0\n","Glucose                     0\n","BloodPressure               0\n","SkinThickness               0\n","Insulin                     0\n","BMI                         0\n","DiabetesPedigreeFunction    0\n","Age                         0\n","Outcome                     0\n","dtype: int64\n"]}]},{"cell_type":"code","source":["# 2) BASELINE (no tailoring, no clustering)\n","#    Pipeline: Standardize -> LogisticRegression\n","# --------------------------------------------------------\n","scaler = StandardScaler()                                       # Create a standard scaler (fit on training data only)\n","logreg = LogisticRegression(                                    # Create Logistic Regression classifier\n","    max_iter=500,                                               # Allow more iterations for convergence\n","    solver=\"liblinear\",                                         # Good solver for small datasets; supports L1/L2\n","    random_state=RANDOM_STATE                                   # Reproducibility\n",")\n","\n","pipe_baseline = Pipeline([                                      # Build a pipeline that scales then classifies\n","    (\"scaler\", scaler),                                         # Step 1: standardize features\n","    (\"clf\", logreg)                                             # Step 2: logistic regression\n","])"],"metadata":{"id":"uR7NLSXAbHcV","executionInfo":{"status":"ok","timestamp":1760859845532,"user_tz":-60,"elapsed":39,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Hyperparam grid for logistic regression (L1/L2 and strength C)\n","param_grid = {                                                  # Hyperparameters to search over\n","    \"clf__penalty\": [\"l1\", \"l2\"],                               # Regularization type: L1 (sparse) or L2 (ridge)\n","    \"clf__C\": [0.01, 0.1, 1, 3, 10]                             # Regularization strength (inverse); larger = weaker reg\n","}"],"metadata":{"id":"Z80FWGjcbPK9","executionInfo":{"status":"ok","timestamp":1760859854781,"user_tz":-60,"elapsed":4,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Stratified split to preserve class balance\n","X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(  # Train/test split once for fair comparison\n","    X_full, y_full, test_size=0.2, stratify=y_full, random_state=RANDOM_STATE\n",")\n","\n","cv = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)  # Stratified CV preserves class ratio\n","\n","gs_base = GridSearchCV(                                         # Cross-validated hyperparameter search\n","    estimator=pipe_baseline,                                    # Our pipeline (scaler + LR)\n","    param_grid=param_grid,                                      # Grid of hyperparameters to test\n","    cv=cv,                                                      # Stratified K-fold\n","    scoring=SCORING,                                            # Optimize F1 score\n","    n_jobs=-1                                                   # Use all CPU cores available\n",")\n","gs_base.fit(X_train_base, y_train_base)                         # Fit CV search on training data\n","\n","baseline_model = gs_base.best_estimator_                        # Extract the best pipeline (scaler + LR with best params)\n","print(\"Baseline best params:\", gs_base.best_params_)            # Show chosen hyperparameters\n","evaluate(baseline_model, X_test_base, y_test_base,              # Evaluate on held-out test set\n","         title=\"Baseline (no tailoring, no clusters)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPvRMAfqbRb-","executionInfo":{"status":"ok","timestamp":1760859872576,"user_tz":-60,"elapsed":7669,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"9ba086c5-c3de-49fa-da45-90e9812b43ec"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline best params: {'clf__C': 0.1, 'clf__penalty': 'l1'}\n","\n","=== Baseline (no tailoring, no clusters) ===\n","              precision    recall  f1-score   support\n","\n","           0      0.743     0.810     0.775       100\n","           1      0.578     0.481     0.525        54\n","\n","    accuracy                          0.695       154\n","   macro avg      0.660     0.646     0.650       154\n","weighted avg      0.685     0.695     0.688       154\n","\n","ROC-AUC: 0.812\n","Confusion matrix:\n"," [[81 19]\n"," [28 26]]\n"]}]},{"cell_type":"code","source":["# ----------------------------------------------------\n","# Engineered features:\n","# - Insulin_over_Glucose: stabilised ratio\n","# - BMI_x_Glucose: interaction capturing joint effect\n","X_tailored = X_full.copy()                                      # Start from original features\n","\n","if {\"Insulin\", \"Glucose\"}.issubset(X_tailored.columns):         # If both columns exist\n","    X_tailored[\"Insulin_over_Glucose\"] = (                      # Create ratio feature (stabilized division)\n","        X_tailored[\"Insulin\"] / (X_tailored[\"Glucose\"] + EPS)   # Add small EPS to avoid divide-by-zero\n","    )\n","\n","if {\"BMI\", \"Glucose\"}.issubset(X_tailored.columns):             # If both columns exist\n","    X_tailored[\"BMI_x_Glucose\"] = (                             # Create interaction feature (product)\n","        X_tailored[\"BMI\"] * X_tailored[\"Glucose\"]\n","    )"],"metadata":{"id":"D9MHl5QIbT6E","executionInfo":{"status":"ok","timestamp":1760859883608,"user_tz":-60,"elapsed":5,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Re-split to simulate \"new feature arrived, re-train\"\n","X_train_tailored, X_test_tailored, y_train_tailored, y_test_tailored = train_test_split(  # New split to simulate \"feature arrived\"\n","    X_tailored, y_full, test_size=0.2, stratify=y_full, random_state=RANDOM_STATE\n",")\n","\n","pipe_tailored = Pipeline([                                      # Same modeling recipe (scale -> LR)\n","    (\"scaler\", StandardScaler()),                               # Scale features\n","    (\"clf\", LogisticRegression(max_iter=500, solver=\"liblinear\", random_state=RANDOM_STATE))\n","])\n","\n","gs_tailored = GridSearchCV(                                     # CV search again (new feature space)\n","    estimator=pipe_tailored,\n","    param_grid=param_grid,\n","    cv=cv,\n","    scoring=SCORING,\n","    n_jobs=-1\n",")\n","gs_tailored.fit(X_train_tailored, y_train_tailored)             # Fit CV on tailored training data\n","\n","tailored_model = gs_tailored.best_estimator_                    # Best pipeline after tailoring\n","print(\"\\nData Tailoring best params:\", gs_tailored.best_params_)# Display hyperparameters chosen\n","evaluate(tailored_model, X_test_tailored, y_test_tailored,      # Evaluate tailored model on test set\n","         title=\"After Data Tailoring (engineered features added)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOyPb9MhbYeQ","executionInfo":{"status":"ok","timestamp":1760859896256,"user_tz":-60,"elapsed":1727,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"6233adeb-edb4-452c-d507-99194deab775"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Data Tailoring best params: {'clf__C': 0.01, 'clf__penalty': 'l2'}\n","\n","=== After Data Tailoring (engineered features added) ===\n","              precision    recall  f1-score   support\n","\n","           0      0.784     0.800     0.792       100\n","           1      0.615     0.593     0.604        54\n","\n","    accuracy                          0.727       154\n","   macro avg      0.700     0.696     0.698       154\n","weighted avg      0.725     0.727     0.726       154\n","\n","ROC-AUC: 0.813\n","Confusion matrix:\n"," [[80 20]\n"," [22 32]]\n"]}]},{"cell_type":"code","source":["# Fit StandardScaler on TRAINING data only for KMeans to avoid leakage.\n","scaler_for_kmeans = StandardScaler().fit(X_train_tailored)      # Fit scaler on TRAIN ONLY (avoid leakage)\n","Z_train_tailored = scaler_for_kmeans.transform(X_train_tailored)# Transform training data to standardized space\n","\n","kmeans = KMeans(                                                # Create KMeans clustering model\n","    n_clusters=N_CLUSTERS,                                      # Number of clusters (phenotypes)\n","    n_init=10,                                                  # Number of random initializations (stability)\n","    random_state=RANDOM_STATE                                   # Reproducibility\n",").fit(Z_train_tailored)                                         # Fit KMeans on TRAIN (standardized)\n","\n","def add_cluster_feature(X, fitted_scaler, fitted_kmeans):\n","    \"\"\"\n","    Append 'cluster_id' predicted by KMeans.\n","    Steps:\n","      1) scale X using the TRAIN-fitted scaler (no leakage),\n","      2) predict cluster labels,\n","      3) return a copy of X with a numeric 'cluster_id' column.\n","    \"\"\"\n","    Z = fitted_scaler.transform(X)                              # Scale with TRAIN statistics\n","    clusters = fitted_kmeans.predict(Z)                         # Predict cluster id for each row\n","    Xc = X.copy()                                               # Copy to avoid modifying original\n","    Xc[\"cluster_id\"] = clusters.astype(\"float64\")               # Add cluster_id as numeric feature\n","    return Xc                                                   # Return extended DataFrame\n","\n","X_train_clustered = add_cluster_feature(                         # Add cluster labels to TRAIN set\n","    X_train_tailored, scaler_for_kmeans, kmeans\n",")\n","X_test_clustered = add_cluster_feature(                          # Add cluster labels to TEST set\n","    X_test_tailored, scaler_for_kmeans, kmeans\n",")\n","\n","pipe_clustered = Pipeline([                                      # Same modeling recipe (scale -> LR)\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", LogisticRegression(max_iter=500, solver=\"liblinear\", random_state=RANDOM_STATE))\n","])\n","\n","gs_clustered = GridSearchCV(                                     # CV search on the \"clustered\" feature space\n","    estimator=pipe_clustered,\n","    param_grid=param_grid,\n","    cv=cv,\n","    scoring=SCORING,\n","    n_jobs=-1\n",")\n","gs_clustered.fit(X_train_clustered, y_train_tailored)            # Train on TRAIN+cluster_id\n","\n","clustered_model = gs_clustered.best_estimator_                   # Best pipeline after adding cluster_id\n","print(\"\\nClustering+Prediction best params:\", gs_clustered.best_params_)  # Show chosen hyperparameters\n","evaluate(clustered_model, X_test_clustered, y_test_tailored,     # Evaluate on TEST+cluster_id\n","         title=\"After Clustering + Prediction (cluster_id added)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Co-UH6rnbbI3","executionInfo":{"status":"ok","timestamp":1760859913797,"user_tz":-60,"elapsed":1064,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"66967898-ee17-46f8-f4c6-033f3bed2a7b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Clustering+Prediction best params: {'clf__C': 0.1, 'clf__penalty': 'l2'}\n","\n","=== After Clustering + Prediction (cluster_id added) ===\n","              precision    recall  f1-score   support\n","\n","           0      0.752     0.790     0.771       100\n","           1      0.571     0.519     0.544        54\n","\n","    accuracy                          0.695       154\n","   macro avg      0.662     0.654     0.657       154\n","weighted avg      0.689     0.695     0.691       154\n","\n","ROC-AUC: 0.817\n","Confusion matrix:\n"," [[79 21]\n"," [26 28]]\n"]}]},{"cell_type":"code","source":["# -----------------------------------------------------------------------\n","# We simulate a meaningful shift by splitting cohorts by Age:\n","# - Cohort_YoungAdults: Age < 40\n","# - Cohort_OlderAdults: Age >= 40\n","#    Plan:\n","#      A) Define two cohorts (YoungAdults vs OlderAdults) using 'Age'\n","#      B) Train an initial model on YoungAdults only\n","#      C) Check drift vs OlderAdults\n","#      D) Adapt: re-learn clusters on COMBINED (Young+Older) and re-tune LR\n","#      E) Evaluate on OlderAdults to confirm the adapted model generalizes\n","# -----------------------------------------------------------------------\n","\n","if \"Age\" in X_tailored.columns:                                  # Prefer to split cohorts by Age if available\n","    mask_young = X_tailored[\"Age\"] < 40                          # Define YoungAdults cohort as Age < 40\n","else:\n","    mask_young = X_tailored[\"Glucose\"] < X_tailored[\"Glucose\"].median()  # Fallback: split by median Glucose\n","\n","X_cohort_young = X_tailored[mask_young].copy()                   # Features for YoungAdults cohort\n","y_cohort_young = y_full[mask_young].copy()                       # Labels for YoungAdults cohort\n","X_cohort_older = X_tailored[~mask_young].copy()                  # Features for OlderAdults cohort\n","y_cohort_older = y_full[~mask_young].copy()                      # Labels for OlderAdults cohort"],"metadata":{"id":"brJKJsR2bflf","executionInfo":{"status":"ok","timestamp":1760859938191,"user_tz":-60,"elapsed":55,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Train/validation within the initial cohort (YoungAdults)\n","X_train_initial, X_valid_initial, y_train_initial, y_valid_initial = train_test_split(  # Train/valid within YoungAdults\n","    X_cohort_young, y_cohort_young, test_size=0.2, stratify=y_cohort_young, random_state=RANDOM_STATE\n",")"],"metadata":{"id":"PoACXUJpblyY","executionInfo":{"status":"ok","timestamp":1760859947162,"user_tz":-60,"elapsed":12,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Include clustering in this cohort-specific model as well (consistent recipe)\n","scaler_initial_for_kmeans = StandardScaler().fit(X_train_initial) # Fit scaler on YoungAdults TRAIN\n","Z_train_initial = scaler_initial_for_kmeans.transform(X_train_initial)  # Standardize YoungAdults TRAIN\n","kmeans_initial = KMeans(                                         # KMeans for YoungAdults cohort\n","    n_clusters=N_CLUSTERS, n_init=10, random_state=RANDOM_STATE\n",").fit(Z_train_initial)                                           # Fit KMeans on standardized TRAIN\n","\n","def add_cluster_initial(X):\n","    \"\"\"Add cluster_id predicted from the YoungAdults-trained KMeans.\"\"\"\n","    Z = scaler_initial_for_kmeans.transform(X)                   # Scale using YoungAdults TRAIN stats\n","    cl = kmeans_initial.predict(Z)                               # Predict cluster id\n","    Xc = X.copy()                                                # Copy to avoid side effects\n","    Xc[\"cluster_id\"] = cl.astype(\"float64\")                      # Add numeric cluster feature\n","    return Xc                                                    # Return extended DataFrame\n","\n","X_train_initial_c = add_cluster_initial(X_train_initial)         # TRAIN with cluster_id (YoungAdults)\n","X_valid_initial_c = add_cluster_initial(X_valid_initial)         # VALID with cluster_id (YoungAdults)\n","\n","pipe_initial = Pipeline([                                        # Scale -> LR (initial cohort model)\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", LogisticRegression(max_iter=500, solver=\"liblinear\", random_state=RANDOM_STATE))\n","])\n","\n","gs_initial = GridSearchCV(                                       # CV search on initial cohort\n","    estimator=pipe_initial,\n","    param_grid=param_grid,\n","    cv=cv,\n","    scoring=SCORING,\n","    n_jobs=-1\n",")\n","gs_initial.fit(X_train_initial_c, y_train_initial)               # Fit on YoungAdults TRAIN (+cluster_id)\n","initial_model = gs_initial.best_estimator_                       # Best initial model\n","print(\"\\nInitial Cohort best params:\", gs_initial.best_params_)  # Show chosen hyperparameters\n","evaluate(initial_model, X_valid_initial_c, y_valid_initial,      # Evaluate on YoungAdults VALID\n","         title=\"Model on Initial Cohort (YoungAdults)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxtQZpvSbn_S","executionInfo":{"status":"ok","timestamp":1760859957285,"user_tz":-60,"elapsed":1002,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"b3ae7e86-51ee-4716-d350-ebe40ab8565e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Initial Cohort best params: {'clf__C': 0.1, 'clf__penalty': 'l2'}\n","\n","=== Model on Initial Cohort (YoungAdults) ===\n","              precision    recall  f1-score   support\n","\n","           0      0.844     0.938     0.889        81\n","           1      0.783     0.562     0.655        32\n","\n","    accuracy                          0.832       113\n","   macro avg      0.814     0.750     0.772       113\n","weighted avg      0.827     0.832     0.823       113\n","\n","ROC-AUC: 0.895\n","Confusion matrix:\n"," [[76  5]\n"," [14 18]]\n"]}]},{"cell_type":"code","source":["# -------- Drift detection against the new cohort (OlderAdults) --------\n","drift_detected = ks_drift(                                       # Compare distributions: YoungAdults TRAIN vs OlderAdults\n","    X_train_initial, X_cohort_older,\n","    cols=list(set(X_train_initial.columns) & set(X_cohort_older.columns))\n",")\n","print(\"\\nDistribution drift vs. Initial Cohort detected?\", drift_detected)  # Print True/False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttpKm0IgbqN-","executionInfo":{"status":"ok","timestamp":1760859966286,"user_tz":-60,"elapsed":6,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"25a1e1c7-902b-4515-94b4-085400e25e74"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Distribution drift vs. Initial Cohort detected? True\n"]}]},{"cell_type":"code","source":["# -------- Adaptation strategy --------\n","# Full adaptation: re-learn clustering on the COMBINED cohorts and re-tune LR.\n","X_combined = pd.concat([X_train_initial, X_cohort_older], axis=0)  # Combine YoungAdults TRAIN + OlderAdults\n","y_combined = pd.concat([y_train_initial, y_cohort_older], axis=0)  # Combine corresponding labels\n","\n","scaler_combined_for_kmeans = StandardScaler().fit(X_combined)    # Fit scaler on the COMBINED data\n","Z_combined = scaler_combined_for_kmeans.transform(X_combined)    # Standardize COMBINED data\n","kmeans_combined = KMeans(                                        # KMeans on COMBINED cohorts (learns both)\n","    n_clusters=N_CLUSTERS, n_init=10, random_state=RANDOM_STATE\n",").fit(Z_combined)                                                # Fit COMBINED KMeans\n","\n","def add_cluster_combined(X):\n","    \"\"\"Add cluster_id predicted from the COMBINED-cohorts KMeans.\"\"\"\n","    Z = scaler_combined_for_kmeans.transform(X)                  # Scale with COMBINED stats\n","    cid = kmeans_combined.predict(Z)                             # Predict clusters in combined space\n","    Xc = X.copy()                                                # Copy input\n","    Xc[\"cluster_id\"] = cid.astype(\"float64\")                     # Add numeric cluster feature\n","    return Xc                                                    # Return extended DataFrame\n","\n","X_combined_c = add_cluster_combined(X_combined)                  # COMBINED set with cluster_id\n","X_older_c    = add_cluster_combined(X_cohort_older)              # OlderAdults set with cluster_id (for eval)\n","\n","pipe_adapted = Pipeline([                                        # Scale -> LR (adapted model)\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", LogisticRegression(max_iter=500, solver=\"liblinear\", random_state=RANDOM_STATE))\n","])\n","\n","gs_adapted = GridSearchCV(                                       # CV search after adaptation\n","    estimator=pipe_adapted,\n","    param_grid=param_grid,\n","    cv=cv,\n","    scoring=SCORING,\n","    n_jobs=-1\n",")\n","gs_adapted.fit(X_combined_c, y_combined)                         # Train adapted model on combined cohorts\n","\n","adapted_model = gs_adapted.best_estimator_                       # Best adapted pipeline\n","print(\"Adapted Model (Combined Cohorts) best params:\", gs_adapted.best_params_)  # Show params\n","evaluate(adapted_model, X_older_c, y_cohort_older,               # Evaluate adapted model on OlderAdults\n","         title=\"After Adaptation (evaluated on OlderAdults)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8w0WRSIbsqN","executionInfo":{"status":"ok","timestamp":1760859978843,"user_tz":-60,"elapsed":1373,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"f75227b4-3c1a-4c3a-e189-e79cd086bed1"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Adapted Model (Combined Cohorts) best params: {'clf__C': 3, 'clf__penalty': 'l2'}\n","\n","=== After Adaptation (evaluated on OlderAdults) ===\n","              precision    recall  f1-score   support\n","\n","           0      0.667     0.727     0.696        99\n","           1      0.727     0.667     0.696       108\n","\n","    accuracy                          0.696       207\n","   macro avg      0.697     0.697     0.696       207\n","weighted avg      0.698     0.696     0.696       207\n","\n","ROC-AUC: 0.747\n","Confusion matrix:\n"," [[72 27]\n"," [36 72]]\n"]}]},{"cell_type":"code","source":["!pip3 install nbconvert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ACQkVY8FbvZK","executionInfo":{"status":"ok","timestamp":1760860038025,"user_tz":-60,"elapsed":10473,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"bbad6bfa-153d-42b2-deeb-732d39174691"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (7.16.6)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (4.13.5)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.7.1)\n","Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.1.6)\n","Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.8.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.3.0)\n","Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.0.3)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.1.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.10.2)\n","Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.10.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nbconvert) (25.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (1.5.1)\n","Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (2.19.2)\n","Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.7.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.7->nbconvert) (4.5.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from nbclient>=0.5.0->nbconvert) (7.4.9)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert) (2.21.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert) (4.25.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert) (2.8)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert) (4.15.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.27.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (0.4)\n","Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n","Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (26.2.1)\n","Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.5.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nsbC677Nb7nu","executionInfo":{"status":"ok","timestamp":1760860071169,"user_tz":-60,"elapsed":11247,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"65dd0186-131a-48be-8a90-13b5ca866760"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Convert the notebook to HTML using the full path\n","!jupyter nbconvert --to html \"/content/drive/MyDrive/Colab Notebooks/Week03- Lab Tutorial - 5 Marks-u2911496.ipynb\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQa0hbzGcDhW","executionInfo":{"status":"ok","timestamp":1760860289968,"user_tz":-60,"elapsed":5925,"user":{"displayName":"Rohit Rawat","userId":"06841028003708941108"}},"outputId":"656f80b8-d293-4637-97ae-e631ec2fa989"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab Notebooks/Week03- Lab Tutorial - 5 Marks-u2911496.ipynb to html\n","[NbConvertApp] Writing 355361 bytes to /content/drive/MyDrive/Colab Notebooks/Week03- Lab Tutorial - 5 Marks-u2911496.html\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"U8gXloQacK84"},"execution_count":null,"outputs":[]}]}